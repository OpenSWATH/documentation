PyProphet
=========

Overview
--------

PyProphet [1]_ is a reimplementation of the mProphet [2]_ algorithm for targeted proteomics. It is particularly optimized for analysis of large scale data sets generated by OpenSWATH or DIANA.

Contact and Support
-------------------

We provide support for PyProphet on the `GitHub repository
<https://github.com/PyProphet/pyprophet/issues>`_.

You can contact the authors `Uwe Schmitt
<https://www.ethz.ch/services/en/organisation/departments/it-services/people/person-detail.html?persid=204514>`_, `Johan Teleman
<https://github.com/fickludd>`_, `Hannes Röst
<http://www.hroest.ch>`_ and `George Rosenberger
<http://www.rosenberger.pro>`_.

Installation
------------
PyProphet is currently available in two flavors:

PyProphet
~~~~~~~~~
`PyProphet
<https://github.com/PyProphet/pyprophet>`_ is the main Python package. It is also available from `PyPI
<https://pypi.python.org/pypi/pyprophet>`_.

Currently PyProphet requires Python 2.7 and several dependencies. Windows users should install Anaconda, Mac and Linux users should be able to install PyProphet directly from PyPI:

.. code-block:: bash

   pip install pyprophet

PyProphet-cli aka Jumbo-PyProphet
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
To deal with larger data sets and to provide error rate control on the level of peptide sequences and proteins for different contexts (run-specific, experiment-wide and global), an extension of PyProphet is in development [4]_. It is optimized to analyse hundreds of runs simultaneously and builds on IBM LSF or OpenLava workflow managers, but the steps can also be executed independently. It can be installed from PyPI:

.. code-block:: bash

   pip install pyprophet
   pip install pyprophet-cli
   pip install pyprophet-brutus-driver

PyProphet-cli can be adapted to other workflow managers by development of lightweight modules replacing ``pyprophet-brutus-driver``.

Tutorial
--------
PyProphet
~~~~~~~~~
An extended tutorial describing a complete OpenSWATH analysis workflow including PyProphet was recently published [3]_ and is also available from `bioRxiv
<http://biorxiv.org/content/early/2016/03/19/044552>`_.

PyProphet-cli aka Jumbo-PyProphet
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
If the three modules have been properly configured, PyProphet jobs can be submitted using the following command:

.. code-block:: bash

   pyprophet-cli run_on_brutus \
   --data-folder="/tmp/openswath_results/" \
   --data-filename-pattern="openswath_output_*.tsv" --sample-factor=0.1 --job-count=10 \
   --extra-args-prepare --extra-group-column=ProteinName \
   --extra-args-score --lambda=0.8


The example works as following:

- --data-folder: /tmp/openswath_results/ contains 10 files, openswath_output_0.tsv - openswath_output_9.tsv.
- --data-filename-pattern: This regular expression is used to grab the correct files.
- --sample-factor: This value can be anything from 0 - 1. We recommend to use 1/(#runs), here 1/10=0.1.
- --job-count: Specifies the number of parallel jobs to submit.
- --extra-args-prepare --extra-group-column=ProteinName: Also compute protein-level q-values
- --extra-args-score --lambda=0.8: Set lambda to 0.8 for q-value estimation.

There are further parameters that can be set, please refer to:

.. code-block:: bash

   pyprophet-cli --help


Alternatively, if pyprophet-brutus-driver is not available or for integration with other workflow managers, it is also possible to execute all steps independently. In the following example, 3 example runs are used:

1. Prepare data

.. code-block:: bash

   pyprophet-cli prepare --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder=/tmp/pyprophet_work/ --separator="tab" --extra-group-column="ProteinName"

2. Subsample

.. code-block:: bash

   pyprophet-cli subsample --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --separator="tab" --job-number 1 --job-count 3 --sample-factor=0.4 &
   pyprophet-cli subsample --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --separator="tab" --job-number 2 --job-count 3 --sample-factor=0.4 &
   pyprophet-cli subsample --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --separator="tab" --job-number 3 --job-count 3 --sample-factor=0.4 &

3. Semi-supervised learning

.. code-block:: bash

   pyprophet-cli learn --work-folder="/tmp/pyprophet_work/" --separator="tab" --ignore-invalid-scores

4. Scoring

.. code-block:: bash

   pyprophet-cli apply_weights --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --separator="tab" --job-number 1 --job-count 3 &
   pyprophet-cli apply_weights --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --separator="tab" --job-number 2 --job-count 3 &
   pyprophet-cli apply_weights --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --separator="tab" --job-number 3 --job-count 3 &

5. Statistical validation

- Run-specific context

.. code-block:: bash

   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_run_specific" --separator="tab" \
   --job-number 1 --job-count 3 --lambda=0.4 --statistics-mode=run-specific --overwrite-results &
   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_run_specific" --separator="tab" \
   --job-number 2 --job-count 3 --lambda=0.4 --statistics-mode=run-specific --overwrite-results &
   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_run_specific" --separator="tab" \
   --job-number 3 --job-count 3 --lambda=0.4 --statistics-mode=run-specific --overwrite-results &

- Experiment-wide context

.. code-block:: bash

   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_experiment_wide" --separator="tab" \
   --job-number 1 --job-count 3 --lambda=0.4 --statistics-mode=experiment-wide &
   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_experiment_wide" --separator="tab" \
   --job-number 2 --job-count 3 --lambda=0.4 --statistics-mode=experiment-wide &
   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_experiment_wide" --separator="tab" \
   --job-number 3 --job-count 3 --lambda=0.4 --statistics-mode=experiment-wide &

- Global context

.. code-block:: bash

   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_global" --separator="tab" \
   --job-number 1 --job-count 3 --lambda=0.4 --statistics-mode=global &
   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_global" --separator="tab" \
   --job-number 2 --job-count 3 --lambda=0.4 --statistics-mode=global --overwrite-results &
   pyprophet-cli score --data-folder="/tmp/openswath_results/" --data-filename-pattern="*.tsv" \
   --work-folder="/tmp/pyprophet_work/" --result-folder="/tmp/pyprophet_result_global" --separator="tab" \
   --job-number 3 --job-count 3 --lambda=0.4 --statistics-mode=global --overwrite-results &

References
----------
.. [1] Teleman J, Röst HL, Rosenberger G, Schmitt U, Malmström L, Malmström J, Levander F. DIANA--algorithmic improvements for analysis of data-independent acquisition MS data. Bioinformatics. 2015 Feb 15;31(4):555-62. doi: 10.1093/bioinformatics/btu686. Epub 2014 Oct 27. PMID: 25348213

.. [2] Reiter L, Rinner O, Picotti P, Hüttenhain R, Beck M, Brusniak MY, Hengartner MO, Aebersold R. mProphet: automated data processing and statistical validation for large-scale SRM experiments. Nat Methods. 2011 May;8(5):430-5. doi: 10.1038/nmeth.1584. Epub 2011 Mar 20. PMID: 21423193

.. [3] Röst HL, Aebersold R, Schubert OT. Automated SWATH Data Analysis Using Targeted Extraction of Ion Chromatograms. Methods Mol Biol. 2017;1550:289-307. doi: 10.1007/978-1-4939-6747-6_20. PMID: 28188537

.. [4] Rosenberger G, Bludau I, Schmitt U, Heusel M, Hunter CL, Liu Y, MacCoss MJ, MacLean BX, Nesvizhskii AI, Pedrioli PGA, Reiter L, Röst HL, Tate S, Ting YS, Collins BC, Aebersold R. Statistical control of peptide and protein error rates in large-scale targeted data-independent acquisition analyses. Nat Methods. 2017 Aug 21. doi: 10.1038/nmeth.4398. PMID: 28825704
